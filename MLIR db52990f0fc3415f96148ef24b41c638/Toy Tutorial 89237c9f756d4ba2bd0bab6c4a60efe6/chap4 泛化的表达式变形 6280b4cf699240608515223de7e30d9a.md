# chap4 泛化的表达式变形

## 形状推理

```cpp
def multiply_transpose(a, b) {
  return transpose(a) * transpose(b);
}

def main() {
  var a<2, 3> = [[1, 2, 3], [4, 5, 6]];
  var b<2, 3> = [1, 2, 3, 4, 5, 6];
  var c = multiply_transpose(a, b);
  var d = multiply_transpose(b, a);
  print(d);
}
```

当我们不进行任何优化生成MLIR表达式的时候，除了在实例化tensor的时候，其他时候并不能知道tensor的shape信息。

![Untitled](chap4%20%E6%B3%9B%E5%8C%96%E7%9A%84%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%8F%98%E5%BD%A2%206280b4cf699240608515223de7e30d9a/Untitled.png)

## inline 内联pass

使用內联pass，可以用定义的函数体替代函数的调用。对于`multiply_transpose`
 这种函数，函数的调用、返回有关的准备和收尾工作的代码往往比函数体本身的代码要大得多。因此，对于这类简单的、使用频繁的小函数，将之声明为内联函数可提高运行效率

> 频繁的函数调用会用巨大的堆栈产生
> 

Dialect提供了`DialectInlinerInterface`接口，mlir提供了处理内联算法的框架，我们只需要继承`DialectInlinerInterface`，然后再实现所需函数，就可以自定义內联的操作，制定表达式变型规则。

```cpp
/// This class defines the interface for handling inlining with Toy operations.
/// We simplify inherit from the base interface class and override
/// the necessary methods.
structToyInlinerInterface :public DialectInlinerInterface {
using DialectInlinerInterface::DialectInlinerInterface;

/// This hook checks to see if the given callable operation is legal to inline
/// into the given call. For Toy this hook can simply return true, as the Toy
/// Call operation is always inlinable.

/// isLegalToInline 是否inline 没看懂怎么判断的
  bool isLegalToInline(Operation *call, Operation *callable,
                       bool wouldBeCloned)constfinal {
return true;
  }

/// This hook checks to see if the given operation is legal to inline into the
/// given region. For Toy this hook can simply return true, as all Toy
/// operations are inlinable.
  bool isLegalToInline(Operation *, Region *, bool,
                       IRMapping &)constfinal {
return true;
  }

/// This hook cheks if the given 'src' region can be inlined into the 'dest'
/// region. The regions here are the bodies of the callable functions. For
/// Toy, any function can be inlined, so we simply return true.
  bool isLegalToInline(Region *dest, Region *src, bool wouldBeCloned,
                       IRMapping &valueMapping)constfinal {
return true;
  }

/// This hook is called when a terminator operation has been inlined. The only
/// terminator that we have in the Toy dialect is the return
/// operation(toy.return). We handle the return by replacing the values
/// previously returned by the call operation with the operands of the
/// return.
  void handleTerminator(Operation *op,
                        ArrayRef<Value> valuesToRepl)constfinal {
// Only "toy.return" needs to be handled here.
auto returnOp = cast<ReturnOp>(op);

// Replace the values directly with the return operands.
    assert(returnOp.getNumOperands() == valuesToRepl.size());
for (constauto &it : llvm::enumerate(returnOp.getOperands()))
      valuesToRepl[it.index()].replaceAllUsesWith(it.value());
  }
};
```

- [ ]  `isLegalToInline`怎么判断的

`handleTerminator` 处理return op(toy中 仅有toy.return op),直接用valuesToRepl 替代 返回值

注册`ToyInlinerInterface`

```cpp
void ToyDialect::initialize() {
  addInterfaces<ToyInlinerInterface>();
}
```

接下来，我们需要提供一个方法让内联器知道，`toy.generic_call`表示函数调用，`toy.func`表示函数，MLIR提供了operation interface 标记一个操作是调用还是被调用，`CallOpInterface`
 and `CallableOpInterface` 比dialect interface 更细粒度，将会对函数调用进行标记，以此告知內联操作函数调用的位置。
添加相应特征

```cpp
def FuncOp : Toy_Op<"func",
    [DeclareOpInterfaceMethods<CallableOpInterface>]> {
  ...
}

def GenericCallOp : Toy_Op<"generic_call",
    [DeclareOpInterfaceMethods<CallOpInterface>]> {
  ...
CallInterfaceCallable GenericCallOp::getCallableForCallee() {
  return getAttrOfType<SymbolRefAttr>("callee");
}

/// Get the argument operands to the called function, this is required by the
/// call interface.
Operation::operand_range GenericCallOp::getArgOperands() { return inputs(); }
```

![Untitled](chap4%20%E6%B3%9B%E5%8C%96%E7%9A%84%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%8F%98%E5%BD%A2%206280b4cf699240608515223de7e30d9a/Untitled%201.png)

添加cast op，因为不知道multiply_transpose 后的shape, inline 需要类型统一，故将tensor<2x3xf64>转为泛化tensor<*xf64>

```llvm
toy.func @multiply_transpose(%arg0: tensor<*xf64>, %arg1: tensor<*xf64>) -> tensor<*xf64> {
  %0 = toy.transpose(%arg0 : tensor<*xf64>) to tensor<*xf64>
  %1 = toy.transpose(%arg1 : tensor<*xf64>) to tensor<*xf64>
  %2 = toy.mul %0, %1 : tensor<*xf64>
  toy.return %2 : tensor<*xf64>
}
toy.func @main() {
  %0 = toy.constant dense<[[1.000000e+00, 2.000000e+00, 3.000000e+00], [4.000000e+00, 5.000000e+00, 6.000000e+00]]> : tensor<2x3xf64>
  %1 = toy.reshape(%0 : tensor<2x3xf64>) to tensor<2x3xf64>
  %2 = toy.constant dense<[1.000000e+00, 2.000000e+00, 3.000000e+00, 4.000000e+00, 5.000000e+00, 6.000000e+00]> : tensor<6xf64>
  %3 = toy.reshape(%2 : tensor<6xf64>) to tensor<2x3xf64>
  %4 = toy.generic_call @multiply_transpose(%1, %3) : (tensor<2x3xf64>, tensor<2x3xf64>) -> tensor<*xf64>
  %5 = toy.generic_call @multiply_transpose(%3, %1) : (tensor<2x3xf64>, tensor<2x3xf64>) -> tensor<*xf64>
  toy.print %5 : tensor<*xf64>
  toy.return
}
```

## 形状推理

1. 使用ODS框架定义**`ShapeInferencePass`类  pm中添加s**hapeInferencePass

```cpp
classShapeInferencePass:public mlir::PassWrapper<ShapeInferencePass, OperationPass<FuncOp>> {
  void runOnOperation()override {
    FuncOp function = getOperation();
    ...
  }
};
std::unique_ptr<mlir::Pass> mlir::toy::createShapeInferencePass() {
return std::make_unique<ShapeInferencePass>();
}
pm.addPass(mlir::createShapeInferencePass());
```

1. 在Opinterface中添加`ShapeInferenceOpInterface`接口
2. 在各operation中声明`ShapeInferenceOpInterface` （似乎可以将Opinterface 理解为特征？）并定义`inferShapes`方法

```cpp
def MulOp : Toy_Op<"mul",
    [..., DeclareOpInterfaceMethods<ShapeInferenceOpInterface>]> {
  ...
}
/// Infer the output shape of the MulOp, this is required by the shape inference
/// interface.
void MulOp::inferShapes() { getResult().setType(getLhs().getType()); }
```

![Untitled](chap4%20%E6%B3%9B%E5%8C%96%E7%9A%84%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%8F%98%E5%BD%A2%206280b4cf699240608515223de7e30d9a/Untitled%202.png)

## 参考文章

[MLIR 实现泛化的表达式变型](https://zhuanlan.zhihu.com/p/106472878)